name: Run DeepSeek Coder 1.3B + Bolt.new AI Dev Environment

on:
  workflow_dispatch:

jobs:
  bolt-ai-environment:
    runs-on: ubuntu-latest
    steps:
    - name: Install Ollama
      run: |
        curl -fsSL https://ollama.ai/install.sh | sh

    - name: Pull DeepSeek Coder 1.3B
      run: |
        ollama rm deepseek-coder:1.3b -f || true
        ollama pull deepseek-coder:1.3b

    - name: Start Ollama Service
      run: |
        sudo ss -K dst localhost dport = 11434 || true
        OLLAMA_HOST=0.0.0.0 OLLAMA_ORIGINS=* ollama serve &
        timeout 180 bash -c 'until ollama list | grep -q "deepseek"; do sleep 10; done'

    - name: Clone Bolt.new Repository
      run: |
        git clone https://github.com/coleam00/bolt.new-any-llm.git
        cd bolt.new-any-llm
        
    - name: Setup Node.js
      uses: actions/setup-node@v3
      with:
        node-version: 18

    - name: Install Dependencies
      run: |
        npm install -g pnpm
        pnpm install

    - name: Configure Environment
      run: |
        cp .env.example .env.local
        echo "OLLAMA_API_BASE_URL=http://localhost:11434" >> .env.local
        echo "DEFAULT_NUM_CTX=8192" >> .env.local

    - name: Build Bolt.new
      run: pnpm run build

    - name: Start Bolt.new Server
      run: |
        pnpm run start &
        timeout 60 bash -c 'until curl -s http://localhost:3000 > /dev/null; do sleep 5; done'

    - name: Install ngrok
      run: |
        wget -q https://bin.equinox.io/c/bNyj1mQVY4c/ngrok-v3-stable-linux-amd64.tgz
        tar -xf ngrok-v3-stable-linux-amd64.tgz
        chmod +x ngrok

    - name: Expose Coding Environment
      env:
        NGROK_TOKEN: ${{ secrets.NGROK_TOKEN }}
      run: |
        ./ngrok config add-authtoken $NGROK_TOKEN
        ./ngrok http 3000

    - name: Print Access URL
      run: |
        curl -s localhost:4040/api/tunnels | jq -r '.tunnels[0].public_url'
